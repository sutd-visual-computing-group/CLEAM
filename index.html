<!doctype html>
<!--
##############################################################
Ignore this boilerplate if you're just trying to edit the text.
Skip to the part that says 'The real text begins here'
##############################################################

Based on this theme: https://github.com/broccolini/dinky , which mentioned that attribution is appreciated. Thanks, broccolini!
-->
<html lang="en">
  <head>
    <base target="_blank">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="citation_title" content="A template for writing scientific papers">
    <meta name="citation_author" content="Andrew G. York">
    <meta name="citation_publication_date" content="2017/01/05">
    <meta name="citation_journal_title" content="Github.io">
    <meta name="citation_pdf_url" content="https://andrewgyork.github.io/publication_template/Publication_template%20by%20AndrewGYork.pdf">
    <title>publication_template by AndrewGYork</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <!--[if lt IE 9]>
    <script src="javascript/html5shiv/html5shiv.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
      <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
    <script src="javascript/scale-fix/scale.fix.js"></script>
    <script src="javascript/python-highlighting/prism.js"></script>
    <script async  src="javascript/Minimal-MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
    <script src="javascript/update_figures.js"></script>
    <script src="javascript/reference_list/reference_list.js"></script>
    <script src="javascript/google-analytics/analytics.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Resources</h1>
        <ul>
          <li class="buttons pdf"><a class="buttons" href="-">Main Manuscript</a></li>
          <li class="buttons pdf"><a class="buttons" href="-">Supplementary</a></li>
          <li class="download"><a class="buttons" href="-">GenData dataset</a></li>
          <li><a class="buttons github" href="-">View On GitHub</a></li>
          <!--<li><a class="buttons pdf" href="./Publication_template%20by%20AndrewGYork.pdf">Download PDF</a></li>-->
        </ul>
        <!--<p class="header">This project is maintained by <a class="header name" href="https://github.com/AndrewGYork">Christopher Teo</a></p>-->
		<p class="header">This project is maintained by <a class="header name">Christopher Teo</a></p>
      </header>
<!--
##############################################################
The real text begins here.
##############################################################
 -->
<section>
<h1>On Measuring Fairness in Generative Models (NeurIPS23) </h1>
<table class="author_list"style="width:100%;border=0px">
  <tr>
    <th>Christopher T.H.Teo</th>
    <th>Milad Abdollahzadeh</th>
    <th>Ngai-man Cheung</th>
  </tr>
 </table>
 <figure id="Figure_1">
<img src="./images/Fig1/Fig1_v6.jpg"
 alt="Figure 1" id="Figure_1_image">
<!--<figcaption><strong>Figure 1: A static figure using a local image.</strong> This image was generated by <code>/figure_generation/figure_1.py</code>.  </figcaption>-->
</figure><p></p>
<h2>Abstract</h2>
<p> Recently, there has been increased interest in fair generative models. In this work,
we conduct, for the first time, an in-depth study on fairness measurement, a
critical component in gauging progress on fair generative models. We make three
main contributions. First, we conduct a study that reveals that contrary to prior
work’s assumption the existing fairness measurement framework has considerable
measurement errors, even when highly accurate sensitive attribute (SA) classifiers
are used. For example, a ResNet-18 for Gender with accuracy ≈ 97% could still
result in an measurement error of 4.98%. This oversight raises concerns about the
accuracy reported in previous works, where relative fairness improvement falls
within these error margins. Second, to address this issue, we propose CLassifier
Error-Aware Measurement (CLEAM), a new framework which uses a statisti-
cal model to account for inaccuracies in SA classifiers. Our proposed CLEAM
reduces measurement errors significantly, e.g., 4.98%→0.62% for StyleGAN2
w.r.t. Gender. CLEAM achieves this with minimal additional overhead. Third,
we utilize CLEAM to measure fairness in important text-to-image generator and
GANs, revealing considerable biases in these models that raise concerns about
their applications. Code and reproducibility instructions are included in Supp. </p>

</body>
</html>
