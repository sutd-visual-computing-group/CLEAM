<!doctype html>
<!--
##############################################################
Ignore this boilerplate if you're just trying to edit the text.
Skip to the part that says 'The real text begins here'
##############################################################

Based on this theme: https://github.com/broccolini/dinky , which mentioned that attribution is appreciated. Thanks, broccolini!
-->
<html lang="en">
  <head>
    <base target="_blank">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="citation_title" content="A template for writing scientific papers">
    <meta name="citation_author" content="Andrew G. York">
    <meta name="citation_publication_date" content="2017/01/05">
    <meta name="citation_journal_title" content="Github.io">
    <meta name="citation_pdf_url" content="https://andrewgyork.github.io/publication_template/Publication_template%20by%20AndrewGYork.pdf">
    <title>publication_template by AndrewGYork</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <!--[if lt IE 9]>
    <script src="javascript/html5shiv/html5shiv.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
      <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
    <script src="javascript/scale-fix/scale.fix.js"></script>
    <script src="javascript/python-highlighting/prism.js"></script>
    <script async  src="javascript/Minimal-MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
    <script src="javascript/update_figures.js"></script>
    <script src="javascript/reference_list/reference_list.js"></script>
    <script src="javascript/google-analytics/analytics.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Resources</h1>
        <ul>
          <li class="buttons pdf"><a class="buttons" href="https://drive.google.com/file/d/1zg45JpUhASTJc4j2GAysRUYgrF8rfCqb/view?usp=sharing">Supplementary</a></li>
          <li><a class="buttons github" href="https://github.com/Bearwithchris/Fair-Generative-Model-via-Transfer-Learning.git">View On GitHub</a></li>
          <!--<li><a class="buttons pdf" href="./Publication_template%20by%20AndrewGYork.pdf">Download PDF</a></li>-->
        </ul>
        <!--<p class="header">This project is maintained by <a class="header name" href="https://github.com/AndrewGYork">Christopher Teo</a></p>-->
		<p class="header">This project is maintained by <a class="header name">Christopher Teo</a></p>
      </header>
<!--
##############################################################
The real text begins here.
##############################################################
 -->
<section>
<h1>Fair Generative Model via Transfer Learning (NeurIPS24) </h1>
<table class="author_list"style="width:100%;border=0px">
  <tr>
    <th>Christopher T.H.Teo</th>
    <th>Milad Abdollahzadeh</th>
    <th>Ngai-man Cheung</th>
  </tr>
 </table>
 <figure id="Figure_1">
<img src="./images/Fig1/Fig1_v6.jpg"
 alt="Figure 1" id="Figure_1_image">
<!--<figcaption><strong>Figure 1: A static figure using a local image.</strong> This image was generated by <code>/figure_generation/figure_1.py</code>.  </figcaption>-->
</figure><p></p>
<h2>Abstract</h2>
<p> This work addresses fair generative models. Dataset biases
have been a major cause of unfairness in deep generative
models. Previous work had proposed to augment large, bi-
ased datasets with small, unbiased reference datasets. Under
this setup, a weakly-supervised approach has been proposed,
which achieves state-of-the-art quality and fairness in gen-
erated samples. In our work, based on this setup, we pro-
pose a simple yet effective approach. Specifically, first, we
propose fairTL, a transfer learning approach to learn fair
generative models. Under fairTL, we pre-train the genera-
tive model with the available large, biased datasets and sub-
sequently adapt the model using the small, unbiased refer-
ence dataset. Our fairTL can learn expressive sample genera-
tion during pre-training, thanks to the large (biased) dataset.
This knowledge is then transferred to the target model dur-
ing adaptation, which also learns to capture the underlying
fair distribution of the small reference dataset. Second, we
propose fairTL++, where we introduce two additional inno-
vations to improve upon fairTL: (i) multiple feedback and
(ii) Linear-Probing followed by Fine-Tuning (LP-FT). Tak-
ing one step further, we consider an alternative, challeng-
ing setup when only a pre-trained (potentially biased) model
is available but the dataset used to pre-train the model is
inaccessible. We demonstrate that our proposed fairTL and
fairTL++ remain very effective under this setup. We note that
previous work requires access to large, biased datasets and
cannot handle this more challenging setup. Extensive exper-
iments show that fairTL and fairTL++ achieve state-of-the-
art in both quality and fairness of generated samples. </p>

</body>
</html>
